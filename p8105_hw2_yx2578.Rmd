---
title: "Homework 2"
author: Vera Xu
output: github_document
---

This is my solution to HW2.

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(readxl)
```


## Problem 1 as demonstrated by Jeff during lecture

First, define a path to the dataset. 

```{r}
path_to_data = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx"
```


Read the Mr. Trashwheel dataset. 

```{r}
trashwheel_df = 
	read_xlsx(
		path = path_to_data,
		sheet = "Mr. Trash Wheel",
		range = cell_cols("A:N")) %>% 
	janitor::clean_names() %>% 
	drop_na(dumpster) %>% 
	mutate(
		sports_balls = round(sports_balls),
		sports_balls = as.integer(sports_balls)
	)
```

Read precipitation data! For 2018 and 2017. 

```{r}
precip_2018 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2018 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>% 
	mutate(year = 2018) %>% 
	relocate(year)
precip_2017 = 
	read_excel(
		"./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
		sheet = "2017 Precipitation",
		skip = 1
	) %>% 
	janitor::clean_names() %>% 
	drop_na(month) %>% 
	mutate(year = 2017) %>% 
	relocate(year)
```

Now combine annual precipitation dataframes. In the following code chunk, I create a "helper" tibble that contains pairs of numeric and character ways of representing month, and then merge that (using month number as a key) with the precipitation dataset. This technique is one I use often when I need to recode a moderate or large number of values for a variable. 

```{r}
month_df = 
	tibble(
		month = 1:12,
		month_name = month.name
	)
precip_df = 
	bind_rows(precip_2018, precip_2017)
precip_df =
	left_join(precip_df, month_df, by = "month")
```

This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash, and stores it in a dumpster. The dataset contains information on year, month, and trash collected, include some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month precipitation data. In this dataset:

* The median number of sports balls found in a dumpster in 2017 was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`
* The total precipitation in 2018 was `r precip_df %>% filter(year == 2018) %>% pull(total) %>% sum()` inches.


## Problem 2

#### Importing, Tidying and description of the NYC Transit data

Import the "NYC_Transit_Subway_Entrance_And_Exit_Data.csv" dataset in the code chunk below:

```{r import NYC Transit data, message = FALSE, warning = FALSE}
p2_df = 
  read_csv(
    file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv"
  ) %>%
  janitor::clean_names() %>% 
  select (line, station_name, station_latitude, station_longitude, 
          route1:route11,  entrance_type, entry, vending, ada) %>%
  mutate(
    entry = recode(entry, "YES" = 1, "NO" = 0),
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)) %>%
  distinct() %>%
  pivot_longer(
    route1:route11,
    values_to = "route_name") %>%
  drop_na(route_name) %>%
  select(-name)
```

This dataset contains NYC Transit information. After cleaning and tidying, it contains the following variables: line, station name, station latitude, station longitude, routes served, entry, vending, entrance type, and ADA compliance status. 
The steps I've used to clean the data so far are:

* Clean column names
* Select the columns as required
* Convert the entry variable from character to a logical variable and convert all route variables as character
* Keep distinct rows only
* Transform the data into long from, values of route1 to route11 variables are stored as route_name, NA values are dropped

After the cleaning and tidying steps above, the cleaned dataset has a dimension of (`r nrow(p2_df)` rows * `r ncol(p2_df)` columns).

The raw dataset is not tidy as there are repeated information, and varialbles used to annotate routes is in the wide form.

#### Answers to Problem 2 question list

* There are `r nrow(distinct(p2_df, station_name, route_name))` distinct stations in this dataset.
* There are `r nrow(filter(p2_df, ada == 'TRUE') %>% distinct(station_name, route_name))` ADA compliant stations.
* There are `r nrow(distinct(p2_df, station_name, route_name)) - nrow(filter(p2_df, vending == "YES" & entry ==1)%>%distinct(station_name, route_name))` station entrances / exits without vending allow entrance, with a  corresponding percentage `r 100*round(1 - (nrow(filter(p2_df, vending == "YES" & entry ==1)%>%distinct(station_name, route_name)) / nrow(distinct(p2_df, station_name, route_name))), digits= 4)`%.

#### Route A specific stations:
* The route number and route name are already distinct when tidying the imported data in the process above.
* There are `r nrow(filter(p2_df, route_name == 'A') %>% distinct(station_name, route_name))` distinct stations serve the A train. Of these stations, `r nrow(filter(p2_df, route_name == 'A' & ada == 'TRUE') %>% distinct(station_name, route_name))` are ADA compliant.

